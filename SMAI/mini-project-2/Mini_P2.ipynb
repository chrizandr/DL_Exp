{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pdb\n",
    "import requests\n",
    "from collections import defaultdict\n",
    "import random \n",
    "import time\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.tree import DecisionTreeClassifier as DTree\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import *\n",
    "\n",
    "from functools import wraps\n",
    "from time import time as _timenow \n",
    "from sys import stderr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CIFAR-10 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar():\n",
    "    \n",
    "    trn_data, trn_labels, tst_data, tst_labels = [], [], [], []\n",
    "    def unpickle(file):\n",
    "        with open(file, 'rb') as fo:\n",
    "            data = pickle.load(fo, encoding='latin1')\n",
    "        return data\n",
    "    \n",
    "    for i in trange(1):\n",
    "        batchName = './data/data_batch_{0}'.format(i + 1)\n",
    "        unpickled = unpickle(batchName)\n",
    "        trn_data.extend(unpickled['data'])\n",
    "        trn_labels.extend(unpickled['labels'])\n",
    "    unpickled = unpickle('./data/test_batch')\n",
    "    tst_data.extend(unpickled['data'])\n",
    "    tst_labels.extend(unpickled['labels'])\n",
    "    return np.array(trn_data), np.array(trn_labels), np.array(tst_data), np.array(tst_labels)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_prep(train_data, mean_img):\n",
    "    ''' pre-processes the given image\n",
    "        performs mean normalization and other such operations'''\n",
    "    train_data = train_data - mean_img\n",
    "    train_data = train_data.astype(np.float)\n",
    "    train_data = train_data * (1 / 255.0)\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality reduction using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def reduce_dim(**kwargs):\n",
    "    ''' performs dimensionality reduction'''\n",
    "    if kwargs['method'] == 'pca':\n",
    "        pca = PCA(n_components=kwargs['n_components'])\n",
    "        transformed_data = pca.fit_transform(kwargs['data'])\n",
    "        return transformed_data, pca\n",
    "    if kwargs['method'] == 'lda':\n",
    "        lda = LDA(n_components=kwargs['n_components'])\n",
    "        transformed_data = lda.fit_transform(kwargs['data'], kwargs['labels'])\n",
    "        return transformed_data, lda\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using kernel SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(X, y, X_val, y_val, **kwargs):\n",
    "    ''' trains a classifier by taking input features\n",
    "        and their respective targets and returns the trained model'''\n",
    "    if kwargs['method'] == 'SVM':\n",
    "        model = SVC(C=kwargs['C'], kernel='linear')\n",
    "    elif kwargs['method'] == 'SVM RBF':\n",
    "        model = SVC(C=kwargs['C'], kernel='rbf', gamma=kwargs['gamma'])\n",
    "    elif kwargs['method'] == 'DT':\n",
    "        model = DTree(criterion=kwargs['criterion'], max_depth=kwargs['max_depth'])\n",
    "    elif kwargs['method'] == 'LogisticRegression':\n",
    "        model = LogisticRegression()\n",
    "    else:\n",
    "        raise ValueError(\"Not a valid method\")\n",
    "    model.fit(X, y)\n",
    "    train_acc = model.score(X, y)\n",
    "    val_acc = model.score(X_val, y_val)\n",
    "    return model, train_acc, val_acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(target, predicted):\n",
    "    f1 = f1_score(target, predicted, average='micro')\n",
    "    acc = accuracy_score(target, predicted)\n",
    "    return f1, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(X, y, model):\n",
    "    '''takes test data and trained classifier model,\n",
    "    performs classification and prints accuracy and f1-score'''\n",
    "    prediction = model.predict(X)\n",
    "    f1, acc = evaluate(y, prediction)\n",
    "    return f1, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_format_data():\n",
    "    trn_data, trn_labels, tst_data, tst_labels = load_cifar()\n",
    "    mean_img = np.mean(trn_data, axis=0)\n",
    "    trn_data, tst_data = image_prep(trn_data, mean_img), image_prep(tst_data, mean_img)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(trn_data, trn_labels, test_size = 0.20) \n",
    "    return X_train, y_train, X_val, y_val, tst_data, tst_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.24it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = load_and_format_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments:\n",
    "\n",
    "We will now try and determine the best possible combination of features as well as models with various hyperparameters for obtaining the best test accuracy on the dataset. We will try the possible combinations below along with a discussion on overfitting and the various results based on varying the hyperparameters/features in each case. The best parameters based on validation scores are selected for obtainging the test accuracy. A summarized table will be presented at the end of the experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Logistic Regression based classifier and raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression + raw data:  train=0.7045, val=0.3195\n"
     ]
    }
   ],
   "source": [
    "model_params = {'method': \"LogisticRegression\"}\n",
    "model, train_acc, val_acc = classify(X_train, y_train, X_val, y_val, **model_params)\n",
    "print(\"Logistic Regression + raw data:  train={}, val={}\".format(train_acc, val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The model overfits on the raw data when no reduction is done.**\n",
    "\n",
    "**Test Accuracy:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test - F1 score: 0.3308   Accuracy: 0.3308\n"
     ]
    }
   ],
   "source": [
    "f1score, accuracy = test(X_test, y_test, model)\n",
    "print('Test - F1 score: {}   Accuracy: {}'.format(f1score, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Logistic Regression based classifier and LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression + LDA: n_components=5, train=0.653375, val=0.2125\n",
      "Logistic Regression + LDA: n_components=9, train=0.8515, val=0.2185\n"
     ]
    }
   ],
   "source": [
    "reduction_params = {'method': \"lda\", \"data\": X_train, \"labels\": y_train}\n",
    "model_params = {'method': \"LogisticRegression\"}\n",
    "\n",
    "n_components = [5, 9]\n",
    "\n",
    "for nc in n_components:\n",
    "    reduction_params['n_components'] = nc\n",
    "    X_reduced, fmodel = reduce_dim(**reduction_params)\n",
    "    X_val_reduced = fmodel.transform(X_val)\n",
    "    model, train_acc, val_acc = classify(X_reduced, y_train, X_val_reduced, y_val, **model_params)\n",
    "    print(\"Logistic Regression + LDA: n_components={}, train={}, val={}\".format(nc, train_acc, val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model seems to overfit for LDA. This is because the reduction in LDA can have a maximum of num_classes-1 as the reduced dimension, for a small number of classes, this is not sufficient to capture the proper structure of the data and hence this leads to overfitting.**\n",
    "\n",
    "**The Test Accuracy for the model is:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test - F1 score: 0.2374   Accuracy: 0.2374\n"
     ]
    }
   ],
   "source": [
    "reduction_params = {'method': \"lda\", \"data\": X_train, \"labels\": y_train}\n",
    "reduction_params['n_components'] = 9\n",
    "X_reduced, fmodel = reduce_dim(**reduction_params)\n",
    "X_val_reduced = fmodel.transform(X_val)\n",
    "model, train_acc, val_acc = classify(X_reduced, y_train, X_val_reduced, y_val, **model_params)\n",
    "\n",
    "X_test_reduced = fmodel.transform(X_test)\n",
    "f1score, accuracy = test(X_test_reduced, y_test, model)\n",
    "print('Test - F1 score: {}   Accuracy: {}'.format(f1score, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Logistic Regression based classifier and PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression + PCA: n_components=50, train=0.38725, val=0.3725\n",
      "Logistic Regression + PCA: n_components=100, train=0.424, val=0.3875\n",
      "Logistic Regression + PCA: n_components=250, train=0.4715, val=0.3725\n",
      "Logistic Regression + PCA: n_components=500, train=0.5315, val=0.353\n",
      "Logistic Regression + PCA: n_components=1000, train=0.630125, val=0.326\n"
     ]
    }
   ],
   "source": [
    "reduction_params = {'method': \"pca\", \"data\": X_train, \"labels\": y_train}\n",
    "model_params = {'method': \"LogisticRegression\"}\n",
    "\n",
    "n_components = [50, 100, 250, 500, 1000]\n",
    "\n",
    "for nc in n_components:\n",
    "    reduction_params['n_components'] = nc\n",
    "    X_reduced, fmodel = reduce_dim(**reduction_params)\n",
    "    X_val_reduced = fmodel.transform(X_val)\n",
    "    model, train_acc, val_acc = classify(X_reduced, y_train, X_val_reduced, y_val, **model_params)\n",
    "    print(\"Logistic Regression + PCA: n_components={}, train={}, val={}\".format(nc, train_acc, val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With less components, we see that the model trains relatively well on both training and validation data. As the number of components increase, we can see that the model starts overfitting on training data. 100 components seem to be the best with relatively close training and validation scores.**\n",
    "\n",
    "**The Test Accuracy for the model is:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test - F1 score: 0.3818   Accuracy: 0.3818\n"
     ]
    }
   ],
   "source": [
    "reduction_params = {'method': \"pca\", \"data\": X_train, \"labels\": y_train}\n",
    "reduction_params['n_components'] = 100\n",
    "X_reduced, fmodel = reduce_dim(**reduction_params)\n",
    "X_val_reduced = fmodel.transform(X_val)\n",
    "model, train_acc, val_acc = classify(X_reduced, y_train, X_val_reduced, y_val, **model_params)\n",
    "\n",
    "X_test_reduced = fmodel.transform(X_test)\n",
    "f1score, accuracy = test(X_test_reduced, y_test, model)\n",
    "print('Test - F1 score: {}   Accuracy: {}'.format(f1score, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Soft Linear SVM and raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soft Linear SVM + raw data: C=0.0001, train=0.3065, val=0.2735\n",
      "Soft Linear SVM + raw data: C=0.01, train=0.515125, val=0.37\n",
      "Soft Linear SVM + raw data: C=0.1, train=0.6925, val=0.3315\n",
      "Soft Linear SVM + raw data: C=1, train=0.939375, val=0.289\n",
      "Soft Linear SVM + raw data: C=10, train=0.999875, val=0.2875\n"
     ]
    }
   ],
   "source": [
    "model_params = {'method': \"SVM\"}\n",
    "C = [1e-4, 1e-2, 0.1, 1, 10]\n",
    "\n",
    "for c in C:\n",
    "    model_params['C'] = c\n",
    "    model, train_acc, val_acc = classify(X_train, y_train, X_val, y_val, **model_params)\n",
    "    print(\"Soft Linear SVM + raw data: C={}, train={}, val={}\".format(c, train_acc, val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The penalty parameter determines the width of the margin, a larger margin allows more misclassification while training, this causes the model to perform well on the training data, but not on the testing/validation data. A good value of C would be one where training and validation accuracy is in the same region.**\n",
    "\n",
    "**Test Accuracy:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test - F1 score: 0.2123   Accuracy: 0.2123\n"
     ]
    }
   ],
   "source": [
    "model_params['C'] = 1e-4\n",
    "model, train_acc, val_acc = classify(X_train, y_train, X_val, y_val, **model_params)\n",
    "f1score, accuracy = test(X_test, y_test, model)\n",
    "print('Test - F1 score: {}   Accuracy: {}'.format(f1score, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Soft Linear SVM and LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soft SVM + LDA: n_components=5, C=0.0001, train=0.1125, val=0.105\n",
      "Soft SVM + LDA: n_components=5, C=0.01, train=0.6415, val=0.207\n",
      "Soft SVM + LDA: n_components=5, C=0.1, train=0.6495, val=0.212\n",
      "Soft SVM + LDA: n_components=5, C=1, train=0.66, val=0.218\n",
      "Soft SVM + LDA: n_components=5, C=10, train=0.648, val=0.2065\n",
      "Soft SVM + LDA: n_components=9, C=0.0001, train=0.111, val=0.102\n",
      "Soft SVM + LDA: n_components=9, C=0.01, train=0.871, val=0.221\n",
      "Soft SVM + LDA: n_components=9, C=0.1, train=0.8775, val=0.216\n",
      "Soft SVM + LDA: n_components=9, C=1, train=0.8535, val=0.2305\n",
      "Soft SVM + LDA: n_components=9, C=10, train=0.867, val=0.2195\n"
     ]
    }
   ],
   "source": [
    "reduction_params = {'method': \"lda\", \"data\": X_train, \"labels\": y_train}\n",
    "model_params = {'method': \"SVM\"}\n",
    "\n",
    "n_components = [5, 9]\n",
    "C = [1e-4, 1e-2, 0.1, 1, 10]\n",
    "\n",
    "for nc in n_components:\n",
    "    reduction_params['n_components'] = nc\n",
    "    X_reduced, fmodel = reduce_dim(**reduction_params)\n",
    "    X_val_reduced = fmodel.transform(X_val)\n",
    "    for c in C:\n",
    "        model_params['C'] = c\n",
    "        model, train_acc, val_acc = classify(X_reduced, y_train, X_val_reduced, y_val, **model_params)\n",
    "        print(\"Soft SVM + LDA: n_components={}, C={}, train={}, val={}\".format(nc, c, train_acc, val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model seems to overfit for LDA except for a very small margin. This is because the reduction in LDA can have a maximum of num_classes-1 as the reduced dimension, for a small number of classes, this is not sufficient to capture the proper structure of large dimensional data such as images and hence this leads to overfitting.**\n",
    "\n",
    "**The Test Accuracy for the model is:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test - F1 score: 0.2378   Accuracy: 0.2378\n"
     ]
    }
   ],
   "source": [
    "reduction_params = {'method': \"lda\", \"data\": X_train, \"labels\": y_train}\n",
    "reduction_params['n_components'] = 5\n",
    "X_reduced, fmodel = reduce_dim(**reduction_params)\n",
    "X_val_reduced = fmodel.transform(X_val)\n",
    "model, train_acc, val_acc = classify(X_reduced, y_train, X_val_reduced, y_val, **model_params)\n",
    "\n",
    "model_params = {'method': \"SVM\", 'C': 1e-4}\n",
    "X_test_reduced = fmodel.transform(X_test)\n",
    "f1score, accuracy = test(X_test_reduced, y_test, model)\n",
    "print('Test - F1 score: {}   Accuracy: {}'.format(f1score, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Soft Linear SVM and PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soft SVM + PCA: n_components=50, C=0.0001, train=0.2125, val=0.191\n",
      "Soft SVM + PCA: n_components=50, C=0.01, train=0.4465, val=0.329\n",
      "Soft SVM + PCA: n_components=50, C=0.1, train=0.4955, val=0.304\n",
      "Soft SVM + PCA: n_components=50, C=1, train=0.5125, val=0.314\n",
      "Soft SVM + PCA: n_components=50, C=10, train=0.479, val=0.2895\n",
      "Soft SVM + PCA: n_components=100, C=0.0001, train=0.2215, val=0.181\n",
      "Soft SVM + PCA: n_components=100, C=0.01, train=0.49, val=0.3315\n",
      "Soft SVM + PCA: n_components=100, C=0.1, train=0.6255, val=0.3135\n",
      "Soft SVM + PCA: n_components=100, C=1, train=0.7125, val=0.2945\n",
      "Soft SVM + PCA: n_components=100, C=10, train=0.736, val=0.278\n",
      "Soft SVM + PCA: n_components=250, C=0.0001, train=0.184, val=0.171\n",
      "Soft SVM + PCA: n_components=250, C=0.01, train=0.5745, val=0.3295\n",
      "Soft SVM + PCA: n_components=250, C=0.1, train=0.7935, val=0.298\n",
      "Soft SVM + PCA: n_components=250, C=1, train=0.977, val=0.2835\n",
      "Soft SVM + PCA: n_components=250, C=10, train=1.0, val=0.2665\n",
      "Soft SVM + PCA: n_components=500, C=0.0001, train=0.1995, val=0.164\n",
      "Soft SVM + PCA: n_components=500, C=0.01, train=0.603, val=0.334\n",
      "Soft SVM + PCA: n_components=500, C=0.1, train=0.9135, val=0.316\n",
      "Soft SVM + PCA: n_components=500, C=1, train=0.9995, val=0.2785\n",
      "Soft SVM + PCA: n_components=500, C=10, train=1.0, val=0.272\n",
      "Soft SVM + PCA: n_components=1000, C=0.0001, train=0.204, val=0.1595\n",
      "Soft SVM + PCA: n_components=1000, C=0.01, train=0.5895, val=0.3275\n",
      "Soft SVM + PCA: n_components=1000, C=0.1, train=0.925, val=0.285\n",
      "Soft SVM + PCA: n_components=1000, C=1, train=1.0, val=0.298\n",
      "Soft SVM + PCA: n_components=1000, C=10, train=1.0, val=0.291\n"
     ]
    }
   ],
   "source": [
    "reduction_params = {'method': \"pca\", \"data\": X_train, \"labels\": y_train}\n",
    "model_params = {'method': \"SVM\"}\n",
    "\n",
    "n_components = [50, 100, 250, 500, 1000]\n",
    "C = [1e-4, 1e-2, 0.1, 1, 10]\n",
    "\n",
    "for nc in n_components:\n",
    "    reduction_params['n_components'] = nc\n",
    "    X_reduced, fmodel = reduce_dim(**reduction_params)\n",
    "    X_val_reduced = fmodel.transform(X_val)\n",
    "    for c in C:\n",
    "        model_params['C'] = c\n",
    "        model, train_acc, val_acc = classify(X_reduced, y_train, X_val_reduced, y_val, **model_params)\n",
    "        print(\"Soft SVM + PCA: n_components={}, C={}, train={}, val={}\".format(nc, c, train_acc, val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With less components, we see that the model trains relatively well on both training and validation data. As the number of components increase, we can see that the model starts overfitting on training data. 100 components seem to be the best with relatively close training and validation scores. Overfitting can also be seen when larger margins are present in the model. A margin with penalty 0.01 seems to be doing relatively well across all cases.**\n",
    "\n",
    "**The Test Accuracy for the model is:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test - F1 score: 0.3494   Accuracy: 0.3494\n"
     ]
    }
   ],
   "source": [
    "reduction_params = {'method': \"pca\", \"data\": X_train, \"labels\": y_train}\n",
    "reduction_params['n_components'] = 100\n",
    "model_params = {'method': \"SVM\", 'C': 0.01}\n",
    "\n",
    "X_reduced, fmodel = reduce_dim(**reduction_params)\n",
    "X_val_reduced = fmodel.transform(X_val)\n",
    "model, train_acc, val_acc = classify(X_reduced, y_train, X_val_reduced, y_val, **model_params)\n",
    "\n",
    "X_test_reduced = fmodel.transform(X_test)\n",
    "f1score, accuracy = test(X_test_reduced, y_test, model)\n",
    "print('Test - F1 score: {}   Accuracy: {}'.format(f1score, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With SVM RBF and raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM RBF + raw data: C=0.01, gamma=0.0003, train=0.1095, val=0.1015\n",
      "SVM RBF + raw data: C=0.1, gamma=0.0003, train=0.161, val=0.1295\n",
      "SVM RBF + raw data: C=1, gamma=0.0003, train=0.3635, val=0.29\n",
      "SVM RBF + raw data: C=0.01, gamma=0.1, train=0.1095, val=0.091\n",
      "SVM RBF + raw data: C=0.01, gamma=1, train=0.1075, val=0.0985\n",
      "SVM RBF + raw data: C=0.01, gamma=10, train=0.223, val=0.105\n",
      "SVM RBF + raw data: C=0.1, gamma=0.1, train=0.113, val=0.105\n",
      "SVM RBF + raw data: C=0.1, gamma=1, train=0.213, val=0.167\n",
      "SVM RBF + raw data: C=0.1, gamma=10, train=0.118, val=0.1015\n",
      "SVM RBF + raw data: C=1, gamma=0.1, train=1.0, val=0.102\n",
      "SVM RBF + raw data: C=1, gamma=1, train=1.0, val=0.0925\n",
      "SVM RBF + raw data: C=1, gamma=10, train=1.0, val=0.1015\n"
     ]
    }
   ],
   "source": [
    "model_params = {'method': \"SVM RBF\"}\n",
    "C = [1e-2, 0.1, 1]\n",
    "gamma = [3e-4, 1e-1, 1, 10]\n",
    "\n",
    "for c in C:\n",
    "    for g in gamma:\n",
    "        model_params['C'] = c\n",
    "        model_params['gamma'] = g\n",
    "        model, train_acc, val_acc = classify(X_train, y_train, X_val, y_val, **model_params)\n",
    "        print(\"SVM RBF + raw data: C={}, gamma={}, train={}, val={}\".format(c, g, train_acc, val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The penalty parameter determines the width of the margin, a larger margin allows more misclassification while training, this causes the model to perform well on the training data, but not on the testing/validation data. A good value of C would be one where training and validation accuracy is in the same region. The value of gamma determines the deviation of the RBF kernel. A good value of gamma would also be one where training and validation accuracy is in the same region.**\n",
    "\n",
    "**Test Accuracy:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test - F1 score: 0.308   Accuracy: 0.308\n"
     ]
    }
   ],
   "source": [
    "model_params['C'] = 1\n",
    "model_params['gamma'] = 3e-4\n",
    "model, train_acc, val_acc = classify(X_train, y_train, X_val, y_val, **model_params)\n",
    "f1score, accuracy = test(X_test, y_test, model)\n",
    "print('Test - F1 score: {}   Accuracy: {}'.format(f1score, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With SVM RBF and LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM RBF + LDA: n_components=9, C=0.01, gamma=0.0003, train=0.112, val=0.104\n",
      "SVM RBF + LDA: n_components=9, C=0.01, gamma=0.1, train=0.171, val=0.102\n",
      "SVM RBF + LDA: n_components=9, C=0.01, gamma=1, train=0.118, val=0.0925\n",
      "SVM RBF + LDA: n_components=9, C=0.1, gamma=0.0003, train=0.1185, val=0.1015\n",
      "SVM RBF + LDA: n_components=9, C=0.1, gamma=0.1, train=0.87, val=0.2195\n",
      "SVM RBF + LDA: n_components=9, C=0.1, gamma=1, train=0.1065, val=0.1105\n",
      "SVM RBF + LDA: n_components=9, C=1, gamma=0.0003, train=0.8475, val=0.2165\n",
      "SVM RBF + LDA: n_components=9, C=1, gamma=0.1, train=0.9145, val=0.211\n",
      "SVM RBF + LDA: n_components=9, C=1, gamma=1, train=1.0, val=0.127\n"
     ]
    }
   ],
   "source": [
    "reduction_params = {'method': \"lda\", \"data\": X_train, \"labels\": y_train}\n",
    "model_params = {'method': \"SVM RBF\"}\n",
    "\n",
    "C = [1e-2, 0.1, 1]\n",
    "gamma = [3e-4, 1e-1, 1]\n",
    "\n",
    "n_components = [9]\n",
    "\n",
    "for nc in n_components:\n",
    "    reduction_params['n_components'] = nc\n",
    "    X_reduced, fmodel = reduce_dim(**reduction_params)\n",
    "    X_val_reduced = fmodel.transform(X_val)\n",
    "    for c in C:\n",
    "        for g in gamma:\n",
    "            model_params['C'] = c\n",
    "            model_params['gamma'] = g\n",
    "            model, train_acc, val_acc = classify(X_reduced, y_train, X_val_reduced, y_val, **model_params)\n",
    "            print(\"SVM RBF + LDA: n_components={}, C={}, gamma={}, train={}, val={}\".format(nc, c, g, train_acc, val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model seems to overfit for LDA except for a very small margin or a small value of gamma. This is because the reduction in LDA can have a maximum of num_classes-1 as the reduced dimension, for a small number of classes, this is not sufficient to capture the proper structure of large dimensional data such as images and hence this leads to overfitting. A smaller gamma also seems to fit well for the low dimensional data.**\n",
    "\n",
    "**The Test Accuracy for the model is:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test - F1 score: 0.1413   Accuracy: 0.1413\n"
     ]
    }
   ],
   "source": [
    "reduction_params = {'method': \"lda\", \"data\": X_train, \"labels\": y_train}\n",
    "reduction_params['n_components'] = 9\n",
    "X_reduced, fmodel = reduce_dim(**reduction_params)\n",
    "X_val_reduced = fmodel.transform(X_val)\n",
    "model, train_acc, val_acc = classify(X_reduced, y_train, X_val_reduced, y_val, **model_params)\n",
    "\n",
    "model_params = {'method': \"SVM RBF\", 'gamma': 3e-4, 'C': 0.1}\n",
    "X_test_reduced = fmodel.transform(X_test)\n",
    "f1score, accuracy = test(X_test_reduced, y_test, model)\n",
    "print('Test - F1 score: {}   Accuracy: {}'.format(f1score, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With SVM RBF and PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM RBF + PCA: n_components=50, C=0.01, gamma=0.0003, train=0.1075, val=0.0985\n",
      "SVM RBF + PCA: n_components=50, C=0.01, gamma=0.1, train=0.1165, val=0.0925\n",
      "SVM RBF + PCA: n_components=50, C=0.01, gamma=1, train=0.115, val=0.0925\n",
      "SVM RBF + PCA: n_components=50, C=0.1, gamma=0.0003, train=0.177, val=0.143\n",
      "SVM RBF + PCA: n_components=50, C=0.1, gamma=0.1, train=0.111, val=0.1015\n",
      "SVM RBF + PCA: n_components=50, C=0.1, gamma=1, train=0.106, val=0.1015\n",
      "SVM RBF + PCA: n_components=50, C=1, gamma=0.0003, train=0.3525, val=0.297\n",
      "SVM RBF + PCA: n_components=50, C=1, gamma=0.1, train=1.0, val=0.1525\n",
      "SVM RBF + PCA: n_components=50, C=1, gamma=1, train=1.0, val=0.1\n",
      "SVM RBF + PCA: n_components=100, C=0.01, gamma=0.0003, train=0.11, val=0.091\n",
      "SVM RBF + PCA: n_components=100, C=0.01, gamma=0.1, train=0.115, val=0.0985\n",
      "SVM RBF + PCA: n_components=100, C=0.01, gamma=1, train=0.1095, val=0.091\n",
      "SVM RBF + PCA: n_components=100, C=0.1, gamma=0.0003, train=0.182, val=0.1515\n",
      "SVM RBF + PCA: n_components=100, C=0.1, gamma=0.1, train=0.1155, val=0.1015\n",
      "SVM RBF + PCA: n_components=100, C=0.1, gamma=1, train=0.111, val=0.091\n",
      "SVM RBF + PCA: n_components=100, C=1, gamma=0.0003, train=0.348, val=0.296\n",
      "SVM RBF + PCA: n_components=100, C=1, gamma=0.1, train=1.0, val=0.1375\n",
      "SVM RBF + PCA: n_components=100, C=1, gamma=1, train=1.0, val=0.111\n",
      "SVM RBF + PCA: n_components=250, C=0.01, gamma=0.0003, train=0.1085, val=0.1105\n",
      "SVM RBF + PCA: n_components=250, C=0.01, gamma=0.1, train=0.223, val=0.0995\n",
      "SVM RBF + PCA: n_components=250, C=0.01, gamma=1, train=0.111, val=0.0925\n",
      "SVM RBF + PCA: n_components=250, C=0.1, gamma=0.0003, train=0.1545, val=0.146\n",
      "SVM RBF + PCA: n_components=250, C=0.1, gamma=0.1, train=0.1165, val=0.1015\n",
      "SVM RBF + PCA: n_components=250, C=0.1, gamma=1, train=0.114, val=0.0925\n",
      "SVM RBF + PCA: n_components=250, C=1, gamma=0.0003, train=0.3555, val=0.2895\n",
      "SVM RBF + PCA: n_components=250, C=1, gamma=0.1, train=1.0, val=0.119\n",
      "SVM RBF + PCA: n_components=250, C=1, gamma=1, train=1.0, val=0.1015\n",
      "SVM RBF + PCA: n_components=500, C=0.01, gamma=0.0003, train=0.111, val=0.0925\n",
      "SVM RBF + PCA: n_components=500, C=0.01, gamma=0.1, train=0.22, val=0.0985\n",
      "SVM RBF + PCA: n_components=500, C=0.01, gamma=1, train=0.1115, val=0.0985\n",
      "SVM RBF + PCA: n_components=500, C=0.1, gamma=0.0003, train=0.1465, val=0.1195\n",
      "SVM RBF + PCA: n_components=500, C=0.1, gamma=0.1, train=0.109, val=0.104\n",
      "SVM RBF + PCA: n_components=500, C=0.1, gamma=1, train=0.11, val=0.105\n",
      "SVM RBF + PCA: n_components=500, C=1, gamma=0.0003, train=0.3745, val=0.286\n",
      "SVM RBF + PCA: n_components=500, C=1, gamma=0.1, train=1.0, val=0.103\n",
      "SVM RBF + PCA: n_components=500, C=1, gamma=1, train=1.0, val=0.1015\n"
     ]
    }
   ],
   "source": [
    "reduction_params = {'method': \"pca\", \"data\": X_train, \"labels\": y_train}\n",
    "model_params = {'method': \"SVM RBF\"}\n",
    "\n",
    "C = [1e-2, 0.1, 1]\n",
    "gamma = [3e-4, 1e-1, 1]\n",
    "\n",
    "n_components = [50, 100, 250, 500]\n",
    "\n",
    "for nc in n_components:\n",
    "    reduction_params['n_components'] = nc\n",
    "    X_reduced, fmodel = reduce_dim(**reduction_params)\n",
    "    X_val_reduced = fmodel.transform(X_val)\n",
    "    for c in C:\n",
    "        for g in gamma:\n",
    "            model_params['C'] = c\n",
    "            model_params['gamma'] = g\n",
    "            model, train_acc, val_acc = classify(X_reduced, y_train, X_val_reduced, y_val, **model_params)\n",
    "            print(\"SVM RBF + PCA: n_components={}, C={}, gamma={}, train={}, val={}\".format(nc, c, g, train_acc, val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With less components, we see that the model trains relatively well on both training and validation data. As the number of components increase, we can see that the model starts overfitting on training data. 50 components seem to be the best with relatively close training and validation scores. Overfitting can also be seen when larger margins are present in the model. A combination of gamma=0.0003 and C=1 seems to be working the best in all cases.**\n",
    "\n",
    "**The Test Accuracy for the model is:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test - F1 score: 0.3077   Accuracy: 0.3077\n"
     ]
    }
   ],
   "source": [
    "reduction_params = {'method': \"pca\", \"data\": X_train, \"labels\": y_train}\n",
    "reduction_params['n_components'] = 50\n",
    "model_params = {'method': \"SVM RBF\", 'C': 1, 'gamma':0.0003}\n",
    "\n",
    "X_reduced, fmodel = reduce_dim(**reduction_params)\n",
    "X_val_reduced = fmodel.transform(X_val)\n",
    "model, train_acc, val_acc = classify(X_reduced, y_train, X_val_reduced, y_val, **model_params)\n",
    "\n",
    "X_test_reduced = fmodel.transform(X_test)\n",
    "f1score, accuracy = test(X_test_reduced, y_test, model)\n",
    "print('Test - F1 score: {}   Accuracy: {}'.format(f1score, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With DTree and raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTree + raw data: max_depth=2, train=0.20025, val=0.181\n",
      "DTree + raw data: max_depth=5, train=0.300375, val=0.2445\n",
      "DTree + raw data: max_depth=10, train=0.587375, val=0.2475\n",
      "DTree + raw data: max_depth=50, train=1.0, val=0.236\n",
      "DTree + raw data: max_depth=100, train=1.0, val=0.237\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_params = {'method': \"DT\", 'criterion': 'gini'}\n",
    "max_depth = [2, 5, 10, 50, 100]\n",
    "\n",
    "for m in max_depth:\n",
    "    model_params['max_depth'] = m\n",
    "    model, train_acc, val_acc = classify(X_train, y_train, X_val, y_val, **model_params)\n",
    "    print(\"DTree + raw data: max_depth={}, train={}, val={}\".format(m, train_acc, val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Max Depth determines the maximum depth of the decision tree, as the depth of the tree increases, we see that more and more training samples are accurately classified, however this also leads to overfitting as the each node contains fewer samples and it is less generalized. A depth of 5 seems to be working well for the raw data.**\n",
    "\n",
    "**Test Accuracy:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test - F1 score: 0.2678   Accuracy: 0.2678\n"
     ]
    }
   ],
   "source": [
    "model_params['max_depth'] = 5\n",
    "\n",
    "model, train_acc, val_acc = classify(X_train, y_train, X_val, y_val, **model_params)\n",
    "f1score, accuracy = test(X_test, y_test, model)\n",
    "print('Test - F1 score: {}   Accuracy: {}'.format(f1score, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With DTree and LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTree + LDA: n_components=5, max_depth=2, train=0.337375, val=0.15\n",
      "DTree + LDA: n_components=5, max_depth=5, train=0.575875, val=0.195\n",
      "DTree + LDA: n_components=5, max_depth=10, train=0.714125, val=0.2035\n",
      "DTree + LDA: n_components=5, max_depth=50, train=1.0, val=0.214\n",
      "DTree + LDA: n_components=5, max_depth=100, train=1.0, val=0.2105\n",
      "DTree + LDA: n_components=9, max_depth=2, train=0.337375, val=0.15\n",
      "DTree + LDA: n_components=9, max_depth=5, train=0.7425, val=0.2\n",
      "DTree + LDA: n_components=9, max_depth=10, train=0.863625, val=0.191\n",
      "DTree + LDA: n_components=9, max_depth=50, train=1.0, val=0.189\n",
      "DTree + LDA: n_components=9, max_depth=100, train=1.0, val=0.186\n"
     ]
    }
   ],
   "source": [
    "reduction_params = {'method': \"lda\", \"data\": X_train, \"labels\": y_train}\n",
    "model_params = {'method': \"DT\", 'criterion': 'gini'}\n",
    "\n",
    "max_depth = [2, 5, 10, 50, 100]\n",
    "n_components = [5, 9]\n",
    "\n",
    "for nc in n_components:\n",
    "    reduction_params['n_components'] = nc\n",
    "    X_reduced, fmodel = reduce_dim(**reduction_params)\n",
    "    X_val_reduced = fmodel.transform(X_val)\n",
    "    for m in max_depth:\n",
    "        model_params['max_depth'] = m\n",
    "        model, train_acc, val_acc = classify(X_reduced, y_train, X_val_reduced, y_val, **model_params)\n",
    "        print(\"DTree + LDA: n_components={}, max_depth={}, train={}, val={}\".format(nc, m, train_acc, val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model seems to overfit for LDA except for trees with small depth. This is because the reduction in LDA can have a maximum of num_classes-1 as the reduced dimension, for a small number of classes, this is not sufficient to capture the proper structure of large dimensional data such as images and hence this leads to overfitting. Smaller trees also seems to fit well for the low dimensional data.**\n",
    "\n",
    "**The Test Accuracy for the model is:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test - F1 score: 0.2032   Accuracy: 0.2032\n"
     ]
    }
   ],
   "source": [
    "reduction_params = {'method': \"lda\", \"data\": X_train, \"labels\": y_train}\n",
    "reduction_params['n_components'] = 9\n",
    "X_reduced, fmodel = reduce_dim(**reduction_params)\n",
    "X_val_reduced = fmodel.transform(X_val)\n",
    "model, train_acc, val_acc = classify(X_reduced, y_train, X_val_reduced, y_val, **model_params)\n",
    "\n",
    "model_params = {'method': \"DT\", 'max_depth': 2, 'criterion': 'gini'}\n",
    "X_test_reduced = fmodel.transform(X_test)\n",
    "f1score, accuracy = test(X_test_reduced, y_test, model)\n",
    "print('Test - F1 score: {}   Accuracy: {}'.format(f1score, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With DTree and PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTree + PCA: n_components=50, max_depth=2, train=0.19525, val=0.1835\n",
      "DTree + PCA: n_components=50, max_depth=5, train=0.289, val=0.242\n",
      "DTree + PCA: n_components=50, max_depth=10, train=0.550125, val=0.2655\n",
      "DTree + PCA: n_components=50, max_depth=50, train=1.0, val=0.237\n",
      "DTree + PCA: n_components=50, max_depth=100, train=1.0, val=0.231\n",
      "DTree + PCA: n_components=100, max_depth=2, train=0.19525, val=0.1835\n",
      "DTree + PCA: n_components=100, max_depth=5, train=0.289375, val=0.2425\n",
      "DTree + PCA: n_components=100, max_depth=10, train=0.5605, val=0.253\n",
      "DTree + PCA: n_components=100, max_depth=50, train=1.0, val=0.226\n",
      "DTree + PCA: n_components=100, max_depth=100, train=1.0, val=0.2315\n",
      "DTree + PCA: n_components=250, max_depth=2, train=0.19525, val=0.1835\n",
      "DTree + PCA: n_components=250, max_depth=5, train=0.289125, val=0.2405\n",
      "DTree + PCA: n_components=250, max_depth=10, train=0.56175, val=0.259\n",
      "DTree + PCA: n_components=250, max_depth=50, train=1.0, val=0.2225\n",
      "DTree + PCA: n_components=250, max_depth=100, train=1.0, val=0.218\n",
      "DTree + PCA: n_components=500, max_depth=2, train=0.19525, val=0.1835\n",
      "DTree + PCA: n_components=500, max_depth=5, train=0.289125, val=0.2405\n",
      "DTree + PCA: n_components=500, max_depth=10, train=0.571625, val=0.248\n",
      "DTree + PCA: n_components=500, max_depth=50, train=1.0, val=0.2155\n",
      "DTree + PCA: n_components=500, max_depth=100, train=1.0, val=0.2095\n"
     ]
    }
   ],
   "source": [
    "reduction_params = {'method': \"pca\", \"data\": X_train, \"labels\": y_train}\n",
    "model_params = {'method': \"DT\", 'criterion': 'gini'}\n",
    "\n",
    "max_depth = [2, 5, 10, 50, 100]\n",
    "\n",
    "n_components = [50, 100, 250, 500]\n",
    "\n",
    "for nc in n_components:\n",
    "    reduction_params['n_components'] = nc\n",
    "    X_reduced, fmodel = reduce_dim(**reduction_params)\n",
    "    X_val_reduced = fmodel.transform(X_val)\n",
    "    for m in max_depth:\n",
    "        model_params['max_depth'] = m\n",
    "        model, train_acc, val_acc = classify(X_reduced, y_train, X_val_reduced, y_val, **model_params)\n",
    "        print(\"DTree + PCA: n_components={}, max_depth={}, train={}, val={}\".format(nc, m, train_acc, val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model seems to be training well when number of components increase, which will always be the case because features are independent of each other in DTrees. The more features, the better the model seems to perform. The model starts overfitting at larger depths. 5 seems to be a good depth without causing overfitting.**\n",
    "\n",
    "**The Test Accuracy for the model is:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test - F1 score: 0.2586   Accuracy: 0.2586\n"
     ]
    }
   ],
   "source": [
    "reduction_params = {'method': \"pca\", \"data\": X_train, \"labels\": y_train}\n",
    "reduction_params['n_components'] = 500\n",
    "model_params = {'method': \"DT\", 'criterion': 'gini', 'max_depth': 5}\n",
    "\n",
    "X_reduced, fmodel = reduce_dim(**reduction_params)\n",
    "X_val_reduced = fmodel.transform(X_val)\n",
    "model, train_acc, val_acc = classify(X_reduced, y_train, X_val_reduced, y_val, **model_params)\n",
    "\n",
    "X_test_reduced = fmodel.transform(X_test)\n",
    "f1score, accuracy = test(X_test_reduced, y_test, model)\n",
    "print('Test - F1 score: {}   Accuracy: {}'.format(f1score, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strategies to avoid overfitting\n",
    "\n",
    "We see in many of the cases, the model overfits the training data and has a poor validation/test accuracy. There are a few ways in which this can be avoided:\n",
    "\n",
    "- Use larger training datasets. More variety in the training data causes models to learn underlying representations of the data rather than find patterns in the training set. This is true for any model that learns parameters for classification(MLP/SVM) or uses the training data for classifying the test set(KNN).\n",
    "- Use models that generalise well. The more generic the model, the better is it's ability to learn the structure of the data. Simple models tend to overfit on complex data relatively easily.\n",
    "- Use regularization. Regularization causes the model parameters to be constrained and hence forces the model to learn much simpler solutions, rather than complex patterns that will overfit the training data.\n",
    "- Use data augmentation to increase the variety of samples in the dataset. Rotating images, scaling, cropping all can be used to create larger datasets with more variety for each class, thus avoiding overfitting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "The following section contains the summarized results for the different experiments along with the best parameters and test accuracy for each of them. The discussion of the experiment and the reason as to why those parameters were chosen were previously discussed in the subsequent experiment section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression parameter selection\n",
    "\n",
    "| Feature | Reduction Parameters | Model Parameters | Training | Validation |\n",
    "|---------|----------------------|------------------|----------|------------|\n",
    "| Raw     | None                 | None             | 0.7045   | 0.3195     |\n",
    "| LDA     | n_components=5       | None             | 0.653375 | 0.2125     |\n",
    "| LDA     | n_components=5       | None             | 0.8515   | 0.2185     |\n",
    "| PCA     | n_components=50      | None             | 0.38725  | 0.3725     |\n",
    "| PCA     | n_components=10      | None             | 0.424    | 0.3875     |\n",
    "| PCA     | n_components=25      | None             | 0.4715   | 0.3725     |\n",
    "| PCA     | n_components=50      | None             | 0.5315   | 0.353      |\n",
    "| PCA     | n_components=1000    | None             | 0.630125 | 0.326      |\n",
    "\n",
    "### Logistic Regression test accuracy (using best parameters)\n",
    "\n",
    "| Feature | Reduction Parameters | Model Parameters | F1 score | Accuracy |\n",
    "|---------|----------------------|------------------|----------|----------|\n",
    "| Raw     | None                 | None             | 0.3308   | 0.3308   |\n",
    "| LDA     | n_components=9       | None             | 0.2374   | 0.2374   |\n",
    "| PCA     | n_components=100     | None             | 0.3818   | 0.3818   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Linear parameter selection\n",
    "\n",
    "| Feature | Reduction Parameters | Model Parameters | Training | Validation |\n",
    "|---------|----------------------|------------------|----------|------------|\n",
    "| Raw     | None                 | C=0.0001         | 0.3065   | 0.2735     |\n",
    "| Raw     | None                 | C=0.01           | 0.515125 | 0.37       |\n",
    "| Raw     | None                 | C=0.1            | 0.6925   | 0.3315     |\n",
    "| Raw     | None                 | C=1              | 0.939375 | 0.289      |\n",
    "| Raw     | None                 | C=10             | 0.999875 | 0.2875     |\n",
    "| LDA     | n_components=5       | C=0.0001         | 0.1125   | 0.105      |\n",
    "| LDA     | n_components=5       | C=0.01           | 0.6415   | 0.207      |\n",
    "| LDA     | n_components=5       | C=0.1            | 0.6495   | 0.212      |\n",
    "| LDA     | n_components=5       | C=1              | 0.66     | 0.218      |\n",
    "| LDA     | n_components=5       | C=10             | 0.648    | 0.2065     |\n",
    "| LDA     | n_components=9       | C=0.0001         | 0.111    | 0.102      |\n",
    "| LDA     | n_components=9       | C=0.01           | 0.871    | 0.221      |\n",
    "| LDA     | n_components=9       | C=0.1            | 0.8775   | 0.216      |\n",
    "| LDA     | n_components=9       | C=1              | 0.8535   | 0.2305     |\n",
    "| LDA     | n_components=9       | C=10             | 0.867    | 0.2195     |\n",
    "| PCA     | n_components=50      | C=0.0001         | 0.2125   | 0.191      |\n",
    "| PCA     | n_components=50      | C=0.01           | 0.4465   | 0.329      |\n",
    "| PCA     | n_components=50      | C=0.1            | 0.4955   | 0.304      |\n",
    "| PCA     | n_components=50      | C=1              | 0.5125   | 0.314      |\n",
    "| PCA     | n_components=50      | C=10             | 0.479    | 0.2895     |\n",
    "| PCA     | n_components=100     | C=0.0001         | 0.2215   | 0.181      |\n",
    "| PCA     | n_components=100     | C=0.01           | 0.49     | 0.3315     |\n",
    "| PCA     | n_components=100     | C=0.1            | 0.6255   | 0.3135     |\n",
    "| PCA     | n_components=100     | C=1              | 0.7125   | 0.2945     |\n",
    "| PCA     | n_components=100     | C=10             | 0.736    | 0.278      |\n",
    "| PCA     | n_components=250     | C=0.0001         | 0.184    | 0.171      |\n",
    "| PCA     | n_components=250     | C=0.01           | 0.5745   | 0.3295     |\n",
    "| PCA     | n_components=250     | C=0.1            | 0.7935   | 0.298      |\n",
    "| PCA     | n_components=250     | C=1              | 0.977    | 0.2835     |\n",
    "| PCA     | n_components=250     | C=10             | 1.0      | 0.2665     |\n",
    "| PCA     | n_components=500     | C=0.0001         | 0.1995   | 0.164      |\n",
    "| PCA     | n_components=500     | C=0.01           | 0.603    | 0.334      |\n",
    "| PCA     | n_components=500     | C=0.1            | 0.9135   | 0.316      |\n",
    "| PCA     | n_components=500     | C=1              | 0.9995   | 0.2785     |\n",
    "| PCA     | n_components=500     | C=10             | 1.0      | 0.272      |\n",
    "| PCA     | n_components=1000    | C=0.0001         | 0.204    | 0.1595     |\n",
    "| PCA     | n_components=1000    | C=0.01           | 0.5895   | 0.3275     |\n",
    "| PCA     | n_components=1000    | C=0.1            | 0.925    | 0.285      |\n",
    "| PCA     | n_components=1000    | C=1              | 1.0      | 0.298      |\n",
    "| PCA     | n_components=1000    | C=10             | 1.0      | 0.291      |\n",
    "\n",
    "### SVM Linear test accuracy (using best parameters)\n",
    "\n",
    "| Feature | Reduction Parameters | Model Parameters | F1 score | Accuracy |\n",
    "|---------|----------------------|------------------|----------|----------|\n",
    "| Raw     | None                 | C=0.0001         | 0.2123   | 0.2123   |\n",
    "| LDA     | n_components=5       | C=0.0001         | 0.2378   | 0.2378   |\n",
    "| PCA     | n_components=100     | C=0.01           | 0.3494   | 0.3494   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM RBF parameter selection\n",
    "\n",
    "| Feature | Reduction Parameters | Model Parameters     | Training | Validation |\n",
    "|---------|----------------------|----------------------|----------|------------|\n",
    "| Raw     | None                 | C=0.01; gamma=0.0003 | 0.1095   | 0.1015     |\n",
    "| Raw     | None                 | C=0.1; gamma=0.0003  | 0.161    | 0.1295     |\n",
    "| Raw     | None                 | C=1; gamma=0.0003    | 0.3635   | 0.29       |\n",
    "| Raw     | None                 | C=0.01; gamma=0.1    | 0.1095   | 0.091      |\n",
    "| Raw     | None                 | C=0.01; gamma=1      | 0.1075   | 0.0985     |\n",
    "| Raw     | None                 | C=0.01; gamma=10     | 0.223    | 0.105      |\n",
    "| Raw     | None                 | C=0.1; gamma=0.1     | 0.113    | 0.105      |\n",
    "| Raw     | None                 | C=0.1; gamma=1       | 0.213    | 0.167      |\n",
    "| Raw     | None                 | C=0.1; gamma=10      | 0.118    | 0.1015     |\n",
    "| Raw     | None                 | C=1; gamma=0.1       | 1.0      | 0.102      |\n",
    "| Raw     | None                 | C=1; gamma=1         | 1.0      | 0.0925     |\n",
    "| Raw     | None                 | C=1; gamma=10        | 1.0      | 0.1015     |\n",
    "| LDA     | n_components=9       | C=0.01; gamma=0.0003 | 0.112    | 0.104      |\n",
    "| LDA     | n_components=9       | C=0.01; gamma=0.1    | 0.171    | 0.102      |\n",
    "| LDA     | n_components=9       | C=0.01; gamma=1      | 0.118    | 0.0925     |\n",
    "| LDA     | n_components=9       | C=0.1; gamma=0.0003  | 0.1185   | 0.1015     |\n",
    "| LDA     | n_components=9       | C=0.1; gamma=0.1     | 0.87     | 0.2195     |\n",
    "| LDA     | n_components=9       | C=0.1; gamma=1       | 0.1065   | 0.1105     |\n",
    "| LDA     | n_components=9       | C=1; gamma=0.0003    | 0.8475   | 0.2165     |\n",
    "| LDA     | n_components=9       | C=1; gamma=0.1       | 0.9145   | 0.211      |\n",
    "| LDA     | n_components=9       | C=1; gamma=1         | 1.0      | 0.127      |\n",
    "| PCA     | n_components=50      | C=0.01; gamma=0.0003 | 0.1075   | 0.0985     |\n",
    "| PCA     | n_components=50      | C=0.01; gamma=0.1    | 0.1165   | 0.0925     |\n",
    "| PCA     | n_components=50      | C=0.01; gamma=1      | 0.115    | 0.0925     |\n",
    "| PCA     | n_components=50      | C=0.1; gamma=0.0003  | 0.177    | 0.143      |\n",
    "| PCA     | n_components=50      | C=0.1; gamma=0.1     | 0.111    | 0.1015     |\n",
    "| PCA     | n_components=50      | C=0.1; gamma=1       | 0.106    | 0.1015     |\n",
    "| PCA     | n_components=50      | C=1; gamma=0.0003    | 0.3525   | 0.297      |\n",
    "| PCA     | n_components=50      | C=1; gamma=0.1       | 1.0      | 0.1525     |\n",
    "| PCA     | n_components=50      | C=1; gamma=1         | 1.0      | 0.1        |\n",
    "| PCA     | n_components=100     | C=0.01; gamma=0.0003 | 0.11     | 0.091      |\n",
    "| PCA     | n_components=100     | C=0.01; gamma=0.1    | 0.115    | 0.0985     |\n",
    "| PCA     | n_components=100     | C=0.01; gamma=1      | 0.1095   | 0.091      |\n",
    "| PCA     | n_components=100     | C=0.1; gamma=0.0003  | 0.182    | 0.1515     |\n",
    "| PCA     | n_components=100     | C=0.1; gamma=0.1     | 0.1155   | 0.1015     |\n",
    "| PCA     | n_components=100     | C=0.1; gamma=1       | 0.111    | 0.091      |\n",
    "| PCA     | n_components=100     | C=1; gamma=0.0003    | 0.348    | 0.296      |\n",
    "| PCA     | n_components=100     | C=1; gamma=0.1       | 1.0      | 0.1375     |\n",
    "| PCA     | n_components=100     | C=1; gamma=1         | 1.0      | 0.111      |\n",
    "| PCA     | n_components=250     | C=0.01; gamma=0.0003 | 0.1085   | 0.1105     |\n",
    "| PCA     | n_components=250     | C=0.01; gamma=0.1    | 0.223    | 0.0995     |\n",
    "| PCA     | n_components=250     | C=0.01; gamma=1      | 0.111    | 0.0925     |\n",
    "| PCA     | n_components=250     | C=0.1; gamma=0.0003  | 0.1545   | 0.146      |\n",
    "| PCA     | n_components=250     | C=0.1; gamma=0.1     | 0.1165   | 0.1015     |\n",
    "| PCA     | n_components=250     | C=0.1; gamma=1       | 0.114    | 0.0925     |\n",
    "| PCA     | n_components=250     | C=1; gamma=0.0003    | 0.3555   | 0.2895     |\n",
    "| PCA     | n_components=250     | C=1; gamma=0.1       | 1.0      | 0.119      |\n",
    "| PCA     | n_components=250     | C=1; gamma=1         | 1.0      | 0.1015     |\n",
    "| PCA     | n_components=500     | C=0.01; gamma=0.0003 | 0.111    | 0.0925     |\n",
    "| PCA     | n_components=500     | C=0.01; gamma=0.1    | 0.22     | 0.0985     |\n",
    "| PCA     | n_components=500     | C=0.01; gamma=1      | 0.1115   | 0.0985     |\n",
    "| PCA     | n_components=500     | C=0.1; gamma=0.0003  | 0.1465   | 0.1195     |\n",
    "| PCA     | n_components=500     | C=0.1; gamma=0.1     | 0.109    | 0.104      |\n",
    "| PCA     | n_components=500     | C=0.1; gamma=1       | 0.11     | 0.105      |\n",
    "| PCA     | n_components=500     | C=1; gamma=0.0003    | 0.3745   | 0.286      |\n",
    "| PCA     | n_components=500     | C=1; gamma=0.1       | 1.0      | 0.103      |\n",
    "| PCA     | n_components=500     | C=1; gamma=1         | 1.0      | 0.1015     |\n",
    "\n",
    "### SVM RBF test accuracy (using best parameters)\n",
    "\n",
    "| Feature | Reduction Parameters | Model Parameters    | F1 score | Accuracy |\n",
    "|---------|----------------------|---------------------|----------|----------|\n",
    "| Raw     | None                 | C=1; gamma=0.0003   | 0.308    | 0.308    |\n",
    "| LDA     | n_components=9       | C=0.1; gamma=0.0003 | 0.1413   | 0.1413   |\n",
    "| PCA     | n_components=50      | C=1; gamma=0.0003   | 0.3077   | 0.3077   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DTree parameter selection\n",
    "\n",
    "| Feature | Reduction Parameters | Model Parameters | Training | Validation |\n",
    "|---------|----------------------|------------------|----------|------------|\n",
    "| Raw     | None                 | max_depth=2      | 0.20025  | 0.181      |\n",
    "| Raw     | None                 | max_depth=5      | 0.300375 | 0.2445     |\n",
    "| Raw     | None                 | max_depth=10     | 0.587375 | 0.2475     |\n",
    "| Raw     | None                 | max_depth=50     | 1.0      | 0.236      |\n",
    "| Raw     | None                 | max_depth=100    | 1.0      | 0.237      |\n",
    "| LDA     | n_components=5       | max_depth=2      | 0.337375 | 0.15       |\n",
    "| LDA     | n_components=5       | max_depth=5      | 0.575875 | 0.195      |\n",
    "| LDA     | n_components=5       | max_depth=10     | 0.714125 | 0.2035     |\n",
    "| LDA     | n_components=5       | max_depth=50     | 1.0      | 0.214      |\n",
    "| LDA     | n_components=5       | max_depth=100    | 1.0      | 0.2105     |\n",
    "| LDA     | n_components=9       | max_depth=2      | 0.337375 | 0.15       |\n",
    "| LDA     | n_components=9       | max_depth=5      | 0.7425   | 0.2        |\n",
    "| LDA     | n_components=9       | max_depth=10     | 0.863625 | 0.191      |\n",
    "| LDA     | n_components=9       | max_depth=50     | 1.0      | 0.189      |\n",
    "| LDA     | n_components=9       | max_depth=100    | 1.0      | 0.186      |\n",
    "| PCA     | n_components=50      | max_depth=2      | 0.19525  | 0.1835     |\n",
    "| PCA     | n_components=50      | max_depth=5      | 0.289    | 0.242      |\n",
    "| PCA     | n_components=50      | max_depth=10     | 0.550125 | 0.2655     |\n",
    "| PCA     | n_components=50      | max_depth=50     | 1.0      | 0.237      |\n",
    "| PCA     | n_components=50      | max_depth=100    | 1.0      | 0.231      |\n",
    "| PCA     | n_components=100     | max_depth=2      | 0.19525  | 0.1835     |\n",
    "| PCA     | n_components=100     | max_depth=5      | 0.289375 | 0.2425     |\n",
    "| PCA     | n_components=100     | max_depth=10     | 0.5605   | 0.253      |\n",
    "| PCA     | n_components=100     | max_depth=50     | 1.0      | 0.226      |\n",
    "| PCA     | n_components=100     | max_depth=100    | 1.0      | 0.2315     |\n",
    "| PCA     | n_components=250     | max_depth=2      | 0.19525  | 0.1835     |\n",
    "| PCA     | n_components=250     | max_depth=5      | 0.289125 | 0.2405     |\n",
    "| PCA     | n_components=250     | max_depth=10     | 0.56175  | 0.259      |\n",
    "| PCA     | n_components=250     | max_depth=50     | 1.0      | 0.2225     |\n",
    "| PCA     | n_components=250     | max_depth=100    | 1.0      | 0.218      |\n",
    "| PCA     | n_components=500     | max_depth=2      | 0.19525  | 0.1835     |\n",
    "| PCA     | n_components=500     | max_depth=5      | 0.289125 | 0.2405     |\n",
    "| PCA     | n_components=500     | max_depth=10     | 0.571625 | 0.248      |\n",
    "| PCA     | n_components=500     | max_depth=50     | 1.0      | 0.2155     |\n",
    "| PCA     | n_components=500     | max_depth=100    | 1.0      | 0.2095     |\n",
    "\n",
    "### DTree test accuracy (using best parameters)\n",
    "\n",
    "| Feature | Reduction Parameters | Model Parameters | F1 score | Accuracy |\n",
    "|---------|----------------------|------------------|----------|----------|\n",
    "| Raw     | None                 | max_depth=5      | 0.2678   | 0.2678   |\n",
    "| LDA     | n_components=9       | max_depth=2      | 0.2032   | 0.2032   |\n",
    "| PCA     | n_components=500     | max_depth=5      | 0.2586   | 0.2586   |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
